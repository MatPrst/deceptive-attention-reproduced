{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp38-cp38-macosx_10_11_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: requests in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/ardsnijders/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=eca2583b1d3326e50f88ad8136e6e6f31a080520cfb84498ca65e4dca62d0dcc\n",
      "  Stored in directory: /Users/ardsnijders/Library/Caches/pip/wheels/7b/78/f4/27d43a65043e1b75dbddaa421b573eddc67e712be4b1c80677\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/ardsnijders/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1282c3eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec558bdb42254094923e4d1581177462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3996e09f9a5c4271909c02c179d7180d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddddf3ed9d7d4cbc9954903d12d5e53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22e6a7cd7cd470890e3dfe9cf54aae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the model we want to use\n",
    "MODEL_NAME = \"bert-base-cased\"\n",
    "\n",
    "# We need to create the model and tokenizer\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print(model.parameters)\n",
    "from pprint import pprint\n",
    "# pprint(vars(model._modules()))\n",
    "print(model._modules['encoder'].layer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertSelfAttention(\n",
      "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._modules['encoder'].layer[0].attention.self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape:  torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "#put the model in eval mode\n",
    "model.eval()\n",
    "\n",
    "sent = \"The animal didn't cross the street because it was too tired\"\n",
    "#Add CLS and SEP Tokens considering it as one sentence\n",
    "sent = \"[CLS] \" + sent + \" [SEP]\"\n",
    "\n",
    "#apply tokenizer and get ids\n",
    "tokenized_text = tokenizer.tokenize(sent)\n",
    "tokenized_text_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "#Convert to torch tensor\n",
    "input = torch.tensor(tokenized_text_ids)\n",
    "\n",
    "print(\"input.shape: \", input.shape) #torch.Size([15]) , N=15 here\n",
    "input = input.unsqueeze(dim=0) #add a dimension \n",
    "\n",
    "#Fwd pass - get output\n",
    "output = model(input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attentions(outputs, layer=0, attention_head=0, avg=False):\n",
    "    '''\n",
    "    get the particular output for a particular layer and attention head\n",
    "    layer -> 0 to 11\n",
    "    attention_head -> 0 to 11\n",
    "    '''\n",
    "    if avg:\n",
    "    #avg over all attention heads in a layer\n",
    "    return outputs[layer].squeeze(0).mean(dim=0)\n",
    "\n",
    "    #return values for a particular attention head inside a specific layer\n",
    "    return outputs[layer].squeeze(0)[attention_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.5687,  0.1763,  0.0672,  ..., -0.3716,  0.1667, -0.1321],\n",
      "         [-0.0058, -0.0217,  0.1018,  ...,  0.1843, -0.3020,  0.3822],\n",
      "         [ 0.3899,  0.0632, -0.0706,  ..., -0.3645, -0.1812, -0.2884],\n",
      "         ...,\n",
      "         [ 0.4359, -0.0335,  0.0881,  ..., -0.5215,  0.6530,  0.3643],\n",
      "         [ 0.1118, -0.3311,  0.0931,  ..., -0.8827, -0.0320, -0.1574],\n",
      "         [ 1.5229,  0.1413, -0.2243,  ..., -0.5624,  0.0394, -0.7298]]]), pooler_output=tensor([[-6.6049e-01,  4.0153e-01,  9.9965e-01, -9.8873e-01,  9.5425e-01,\n",
      "          9.2909e-01,  9.8409e-01, -9.9621e-01, -9.6883e-01, -6.4378e-01,\n",
      "          9.7436e-01,  9.9693e-01, -9.9912e-01, -9.9950e-01,  9.0103e-01,\n",
      "         -9.6699e-01,  9.8516e-01, -5.1332e-01, -9.9988e-01, -8.8926e-01,\n",
      "         -6.0914e-01, -9.9966e-01,  3.5943e-01,  9.7838e-01,  9.7174e-01,\n",
      "          5.3969e-02,  9.7922e-01,  9.9986e-01,  9.2669e-01, -6.1083e-01,\n",
      "          1.7518e-01, -9.8255e-01,  9.4109e-01, -9.9743e-01,  9.6134e-02,\n",
      "          1.8987e-01,  8.5391e-01, -1.9700e-01,  9.2979e-01, -9.3123e-01,\n",
      "         -7.2593e-01, -9.4379e-01,  6.5020e-01, -4.9112e-01,  9.3355e-01,\n",
      "          1.9066e-01, -1.2039e-01, -6.9664e-02, -3.4035e-02,  9.9898e-01,\n",
      "         -9.6572e-01,  9.6106e-01, -9.9770e-01,  9.8374e-01,  9.9073e-01,\n",
      "          3.3172e-01,  9.9159e-01,  1.1049e-01, -9.9946e-01, -1.0263e-02,\n",
      "          9.3599e-01,  3.6022e-01,  9.4264e-01, -4.8717e-02,  5.7111e-01,\n",
      "         -2.0189e-01, -8.8454e-01,  1.4869e-01, -4.9433e-01,  3.0295e-01,\n",
      "          4.6765e-01,  2.9108e-01,  9.7776e-01, -8.5481e-01,  3.1970e-02,\n",
      "         -8.5294e-01,  1.5648e-01, -9.9967e-01,  9.5765e-01,  9.9986e-01,\n",
      "          9.1061e-01, -9.9916e-01,  9.9042e-01, -2.3025e-01, -8.3681e-01,\n",
      "          8.2411e-01, -9.9951e-01, -9.9841e-01,  2.2676e-02, -6.0064e-01,\n",
      "          8.8403e-01, -9.8145e-01,  5.7562e-01, -9.3552e-01,  9.9992e-01,\n",
      "         -9.4495e-01, -1.5428e-01,  3.1733e-01,  9.5233e-01, -6.4125e-01,\n",
      "         -6.2909e-01,  9.5377e-01,  9.9948e-01, -9.9834e-01,  9.9926e-01,\n",
      "          7.6016e-01, -9.0344e-01, -8.8758e-01,  9.3775e-01, -5.9604e-02,\n",
      "          9.8294e-01, -9.8573e-01, -8.2663e-01, -7.1632e-02,  9.4582e-01,\n",
      "         -8.4795e-01,  9.7860e-01,  9.6862e-01, -2.9154e-01,  9.9991e-01,\n",
      "         -1.0336e-01,  9.7771e-01,  9.9713e-01,  9.5921e-01, -9.0631e-01,\n",
      "         -1.6313e-01, -7.9557e-01,  9.1665e-01, -6.4943e-01, -2.0853e-01,\n",
      "          7.0760e-01, -9.8815e-01, -9.9902e-01,  9.9878e-01, -2.0567e-01,\n",
      "          9.9990e-01, -9.9796e-01,  9.9671e-01, -9.9978e-01, -8.8442e-01,\n",
      "         -8.0704e-01, -8.5493e-02, -9.9021e-01, -2.0611e-01,  9.8360e-01,\n",
      "         -4.4203e-02, -9.4152e-01, -8.2779e-01,  5.5685e-01, -9.0987e-01,\n",
      "          3.0679e-01,  6.9989e-01, -9.4786e-01,  9.4157e-01,  9.9870e-01,\n",
      "          9.6667e-01,  9.8937e-01,  1.7861e-01, -9.6807e-01,  9.3475e-01,\n",
      "          9.7628e-01, -9.9880e-01,  9.3291e-01, -9.9747e-01,  9.9760e-01,\n",
      "          9.5382e-01,  8.5588e-01, -9.9808e-01,  9.9973e-01, -8.2457e-01,\n",
      "         -1.3353e-01,  3.7875e-01,  6.0861e-02, -9.9960e-01,  3.7774e-01,\n",
      "          3.3646e-01,  7.3755e-01,  9.9796e-01, -9.9149e-01,  9.9840e-01,\n",
      "          5.0804e-01,  2.4968e-01,  6.6248e-01,  9.9936e-01, -9.9255e-01,\n",
      "         -9.7318e-01, -9.7606e-01,  2.6907e-01,  8.5286e-01,  8.6956e-01,\n",
      "          1.3704e-01,  9.5761e-01,  9.9931e-01,  5.6853e-01, -9.9587e-01,\n",
      "         -3.6867e-01,  9.6392e-01, -8.6701e-03,  9.9990e-01, -7.5294e-01,\n",
      "         -9.9935e-01, -9.2833e-01,  9.6775e-01,  9.9414e-01, -1.8668e-01,\n",
      "          9.8309e-01, -7.6732e-01, -4.0577e-01,  9.9095e-01, -8.9238e-01,\n",
      "          9.9925e-01,  2.5348e-01,  8.8016e-01,  8.7272e-01,  9.8735e-01,\n",
      "         -8.3277e-01, -1.3415e-01,  2.7080e-01, -7.1938e-01,  9.9960e-01,\n",
      "         -9.9892e-01, -2.0429e-01,  4.2838e-01, -9.8770e-01, -9.9593e-01,\n",
      "          9.7256e-01,  1.2216e-01, -9.1309e-01, -1.5262e-01,  8.6147e-01,\n",
      "          2.3610e-01,  9.3006e-01,  9.8197e-01, -7.4093e-01, -7.8769e-01,\n",
      "         -9.9946e-01, -9.9892e-01, -8.5994e-01, -9.7935e-01, -3.2519e-02,\n",
      "          6.5239e-01, -3.2261e-01, -8.8361e-01, -9.9934e-01,  9.6043e-01,\n",
      "          8.0987e-01, -9.0722e-01,  9.0303e-02, -7.7018e-01, -9.9920e-01,\n",
      "          8.7361e-01, -9.2137e-01, -9.9702e-01,  9.9867e-01, -9.3259e-01,\n",
      "          9.9760e-01,  9.5711e-01, -9.9144e-01,  8.4840e-01, -9.9944e-01,\n",
      "         -1.5152e-01, -9.6369e-01,  4.3950e-01,  9.0658e-01, -8.7715e-01,\n",
      "          5.0081e-02,  9.8661e-01, -9.6938e-01, -7.1916e-01,  7.2488e-01,\n",
      "         -9.9975e-01,  8.9541e-01, -1.4411e-01,  9.9808e-01,  9.4537e-01,\n",
      "         -2.4878e-01,  9.7509e-01,  9.2861e-01, -9.7643e-01, -9.9944e-01,\n",
      "          8.9887e-01,  6.6481e-01, -9.8834e-01, -1.1171e-01,  9.9976e-01,\n",
      "         -9.9944e-01, -7.5268e-01, -9.1909e-01, -9.8594e-01, -9.9911e-01,\n",
      "          3.0733e-01, -9.0840e-01,  3.3194e-01,  9.6995e-01,  4.4846e-01,\n",
      "          3.0649e-01,  9.8553e-01,  9.7739e-01,  2.9966e-01, -2.9902e-01,\n",
      "         -2.8762e-02, -9.5511e-01, -7.4924e-01,  7.7142e-01,  1.6971e-01,\n",
      "         -9.9988e-01,  9.9953e-01, -9.8975e-01,  9.4016e-01,  9.2434e-01,\n",
      "         -9.9825e-01,  8.5664e-01,  1.7613e-01, -9.8196e-01, -2.0927e-02,\n",
      "          9.9970e-01,  9.7953e-01,  1.0427e-02,  4.7707e-02,  8.9845e-01,\n",
      "         -2.8047e-01,  8.3476e-01, -9.2641e-01, -7.1416e-01,  7.6956e-02,\n",
      "         -9.0419e-01,  9.9202e-01,  8.0314e-01, -9.8576e-01,  9.9812e-01,\n",
      "          1.0681e-01,  6.5040e-01, -8.9053e-01,  7.8929e-01,  9.7764e-01,\n",
      "         -3.5374e-02, -5.9414e-01, -1.2286e-02,  2.8781e-01, -9.8833e-01,\n",
      "          1.2596e-01, -9.9883e-01, -4.4758e-01,  9.7993e-01,  9.8122e-01,\n",
      "         -9.9064e-01,  9.7136e-01, -5.0783e-02,  9.2813e-01, -9.9934e-01,\n",
      "          9.9993e-01, -9.9322e-01,  3.2472e-02,  8.2918e-01, -9.0283e-01,\n",
      "         -5.8895e-01,  9.8265e-01,  9.9255e-01,  9.8386e-01, -9.2326e-01,\n",
      "         -7.6972e-01,  9.1036e-01,  9.5559e-01, -9.8803e-01, -1.0005e-01,\n",
      "         -9.9975e-01, -8.2356e-01,  9.9061e-01,  9.9928e-01,  2.1921e-02,\n",
      "          3.5872e-01, -9.9902e-01,  9.6488e-01, -9.0146e-01, -9.1407e-01,\n",
      "         -2.7967e-02, -8.3714e-01,  6.6445e-01,  9.9897e-01, -6.6184e-01,\n",
      "          7.7645e-01,  1.3912e-01, -9.7679e-01,  8.4184e-01,  8.1862e-01,\n",
      "          9.9956e-01, -9.6229e-01,  5.7253e-01,  9.7746e-01, -1.3309e-01,\n",
      "         -7.1787e-01,  5.2984e-01,  9.9958e-01, -9.8713e-01, -1.4252e-01,\n",
      "         -9.9890e-01, -1.8837e-02, -7.4979e-01, -2.2529e-01, -7.9952e-01,\n",
      "          8.7678e-03, -8.5134e-01,  9.7972e-01,  4.7484e-01,  6.7430e-01,\n",
      "         -4.6006e-01,  9.6224e-01, -3.9378e-01, -3.2492e-02, -2.6466e-01,\n",
      "         -3.7830e-01,  4.2660e-01,  3.7027e-01,  9.7509e-01, -9.7668e-01,\n",
      "          9.9907e-01, -5.4817e-01, -9.9987e-01, -9.9869e-01, -8.8381e-01,\n",
      "         -9.9836e-01,  9.1289e-01, -9.8187e-01,  9.8047e-01,  9.3422e-01,\n",
      "         -9.9929e-01, -9.9969e-01, -9.9092e-01, -9.6104e-01,  9.1101e-01,\n",
      "          6.9520e-01,  4.8495e-02,  4.7552e-01, -4.2501e-01, -1.8825e-03,\n",
      "         -1.8939e-01, -8.1305e-04, -9.4057e-01, -7.3752e-01, -9.9952e-01,\n",
      "          8.4640e-01, -9.9985e-01, -7.9746e-01,  9.9877e-01, -9.9809e-01,\n",
      "         -9.3853e-01, -9.0050e-01, -8.2595e-01, -8.6650e-01,  3.7265e-01,\n",
      "          9.7624e-01, -1.2237e-01, -8.1493e-01, -9.9810e-01,  9.7383e-01,\n",
      "         -8.5715e-01,  6.9613e-02, -8.6123e-01, -9.6849e-01,  9.9939e-01,\n",
      "          9.3009e-01, -3.4011e-01, -6.2979e-02, -9.9785e-01,  9.9292e-01,\n",
      "         -9.5695e-01, -9.2576e-01, -9.7611e-01,  5.0735e-02, -9.3295e-01,\n",
      "         -9.9946e-01, -8.1792e-02,  9.9852e-01,  9.8684e-01,  9.6993e-01,\n",
      "          1.7067e-01, -3.6572e-01, -9.3348e-01,  5.0905e-02, -9.9981e-01,\n",
      "          8.7799e-01,  8.7900e-01, -9.7959e-01, -9.1110e-01,  9.8831e-01,\n",
      "          9.6499e-01, -9.5604e-01, -9.8361e-01,  9.4114e-01,  3.6521e-01,\n",
      "          9.5354e-01, -8.7683e-01, -3.0916e-01,  2.9454e-01, -7.8318e-03,\n",
      "         -9.8122e-01, -8.8149e-01,  9.9159e-01, -9.9959e-01,  9.7299e-01,\n",
      "          9.9744e-01,  9.9952e-01, -2.6399e-01,  5.2825e-02, -9.8767e-01,\n",
      "         -9.5538e-01, -6.1184e-01,  3.6594e-01, -9.9979e-01,  9.9973e-01,\n",
      "         -9.9990e-01,  5.5880e-01, -8.2662e-01,  9.4958e-01,  9.8376e-01,\n",
      "         -3.1384e-01, -9.9973e-01, -9.9945e-01,  7.5231e-01,  1.6882e-01,\n",
      "          9.8377e-01,  3.7415e-01,  1.5690e-01, -8.3077e-01, -4.4937e-01,\n",
      "          9.9344e-01, -9.6844e-01, -9.3501e-01, -9.9942e-01,  9.9918e-01,\n",
      "          7.2221e-01, -9.9683e-01,  9.9650e-01, -9.9854e-01,  8.7567e-01,\n",
      "          9.5437e-01,  8.0443e-01,  9.6924e-01, -9.9963e-01,  9.9989e-01,\n",
      "         -9.9934e-01,  9.9340e-01, -9.9991e-01, -9.9965e-01,  9.9952e-01,\n",
      "         -9.8407e-01, -8.6017e-01, -9.9922e-01, -9.9881e-01,  6.5894e-01,\n",
      "          5.2293e-02, -3.7868e-01,  9.7863e-01, -9.9952e-01, -9.9682e-01,\n",
      "         -1.2144e-02, -9.6336e-01, -8.9152e-01,  9.9778e-01, -7.4339e-01,\n",
      "          9.8243e-01, -1.9379e-01,  9.5311e-01,  4.3107e-01,  9.9841e-01,\n",
      "          9.7125e-01, -8.2889e-01, -9.0365e-01, -9.8801e-01,  9.6842e-01,\n",
      "         -7.1227e-01,  3.2389e-01,  9.4182e-01,  1.7510e-01, -8.7151e-01,\n",
      "          2.5706e-01, -9.9483e-01,  4.5911e-01,  3.3542e-01,  9.2995e-01,\n",
      "          9.6095e-01,  8.1570e-01, -1.4543e-01, -5.9348e-01, -2.3039e-01,\n",
      "         -9.8618e-01,  5.3051e-01, -9.9896e-01,  9.6136e-01, -9.6841e-01,\n",
      "         -6.0165e-03, -3.0995e-01,  3.9852e-02, -9.7486e-01,  9.9920e-01,\n",
      "          9.9636e-01, -9.6602e-01, -8.5623e-02,  9.7610e-01, -7.8423e-01,\n",
      "          9.7951e-01, -9.8415e-01,  6.0850e-02,  9.6069e-01, -7.9542e-01,\n",
      "          9.6949e-01,  2.3147e-01, -6.1858e-02,  9.3539e-01, -9.8861e-01,\n",
      "         -9.1915e-01, -6.5005e-01,  3.8717e-01,  6.1429e-02, -9.6016e-01,\n",
      "         -2.2903e-02,  9.9330e-01, -2.6644e-01, -9.9928e-01,  9.7058e-01,\n",
      "         -9.9849e-01, -1.0689e-01,  9.6564e-01, -7.8788e-01,  9.9974e-01,\n",
      "         -8.2302e-01,  1.1530e-01,  3.2511e-01, -9.9944e-01, -9.9946e-01,\n",
      "         -1.6691e-02, -1.0604e-01, -9.6815e-01,  9.9966e-01, -7.0909e-02,\n",
      "          9.2156e-01, -9.9962e-01,  3.0065e-01,  9.9806e-01,  3.3456e-01,\n",
      "          8.6330e-01, -6.8984e-01, -9.6537e-01, -9.6501e-01, -4.7712e-01,\n",
      "         -3.2604e-02,  9.1573e-01, -9.9006e-01, -9.2528e-01, -8.2740e-01,\n",
      "          9.9981e-01, -9.9541e-01, -8.7102e-01, -9.8659e-01,  6.2831e-01,\n",
      "          8.7906e-01,  4.0535e-01,  1.1234e-01, -9.1423e-01,  9.5248e-01,\n",
      "         -9.2349e-01,  9.9305e-01, -9.8877e-01, -9.9301e-01,  9.9938e-01,\n",
      "          9.4315e-01, -9.9750e-01,  4.7650e-02, -1.5013e-01,  2.2409e-01,\n",
      "          2.4193e-01,  8.2266e-01, -9.7372e-01, -1.9779e-01, -9.9191e-01,\n",
      "          9.6079e-01, -9.1312e-01, -9.8312e-01, -3.7607e-01, -3.5486e-01,\n",
      "         -9.2924e-01,  9.8362e-01,  9.5746e-01,  9.9980e-01, -9.9946e-01,\n",
      "          7.6284e-01,  4.0646e-02,  9.9825e-01,  4.2931e-02, -5.7612e-01,\n",
      "          9.4775e-01,  9.9910e-01, -7.8181e-01,  9.3861e-01, -1.7193e-01,\n",
      "          1.0897e-02,  3.4717e-01, -4.7435e-01,  9.9855e-01, -9.5921e-01,\n",
      "         -1.7230e-01, -9.7258e-01, -9.9973e-01,  9.9977e-01,  5.2467e-02,\n",
      "          9.8067e-01,  2.3239e-01,  8.2045e-01, -8.3220e-01,  9.7820e-01,\n",
      "         -9.8753e-01, -8.7173e-01, -9.9990e-01, -3.9470e-02, -9.6135e-01,\n",
      "         -9.8663e-01, -3.4965e-02,  9.7785e-01, -9.9907e-01, -9.8495e-01,\n",
      "         -5.2859e-01, -9.9990e-01,  9.6645e-01, -9.9342e-01, -8.7623e-01,\n",
      "         -9.7700e-01,  9.9927e-01, -1.4053e-01, -8.2553e-01,  9.6701e-01,\n",
      "         -9.6542e-01,  9.6775e-01,  9.8177e-01, -6.7549e-01,  2.1765e-01,\n",
      "          6.5107e-02, -7.3089e-01, -9.9725e-01, -9.5546e-01, -9.5624e-01,\n",
      "          9.1861e-01, -9.8275e-01, -8.7884e-01,  9.9176e-01,  9.8059e-01,\n",
      "         -9.9811e-01, -9.9090e-01,  9.9810e-01,  1.2560e-01,  9.8174e-01,\n",
      "         -4.2838e-01, -9.9952e-01, -9.9973e-01,  1.4998e-01, -1.3154e-02,\n",
      "          9.9213e-01, -3.4768e-01,  8.5859e-01,  7.4685e-01, -5.6562e-01,\n",
      "          6.7502e-01, -6.2599e-01, -2.8119e-01, -5.4906e-01, -6.5497e-02,\n",
      "          9.9988e-01, -8.5065e-01,  9.8816e-01]]), hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
