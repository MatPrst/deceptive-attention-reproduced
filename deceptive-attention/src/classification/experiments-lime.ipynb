{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments: Fooling Lime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from data_utils import read_data\n",
    "from log_utils import setup_logger\n",
    "from train_utils import *\n",
    "from train_utils import LossConfig\n",
    "from lime_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_type = \"emb-att\"\n",
    "# emb_size = 123\n",
    "# hid_size = 123\n",
    "# task_name = 'occupation-classification'\n",
    "# best_epoch = 1\n",
    "# seed = 1\n",
    "# # c_hammer = 0.0\n",
    "# c_entropy = 0.0\n",
    "# clip_vocab = True\n",
    "# block_words = ['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n",
    "#\n",
    "# train, dev, test, n_words, i2w, i2t, n_tags = read_data(task_name,model_type,clip_vocab, block_words)\n",
    "#\n",
    "# model = get_trained_model(model_type, task_name, best_epoch, seed, c_hammer, c_entropy, n_words, emb_size, hid_size, n_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test\n",
    "For three different manipulations: 0.0 (no manipulation), 0.1, 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data:\n",
      "\toccupation-classification\n",
      "Reading data:\n",
      "\toccupation-classification\n",
      "Using block words:\n",
      "\t['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n",
      "Using block words:\n",
      "\t['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n"
     ]
    }
   ],
   "source": [
    "# model_type = \"emb-att\"\n",
    "# c_entropy = 0.0\n",
    "# clip_vocab = True\n",
    "# block_words = ['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n",
    "# seed = 1\n",
    "#\n",
    "# c_hammers = [0.0, 0.1, 1.0]\n",
    "# tasks = ['sst-wiki', 'pronoun', 'occupation-classification']\n",
    "# best_epochs = [1, 2, 1]\n",
    "#\n",
    "# # for task in tasks:\n",
    "# # for now only for single task\n",
    "# task = tasks[2]\n",
    "#\n",
    "# # for c_hammer in c_hammers:\n",
    "# # for now only for single hammer\n",
    "# loss_config = LossConfig(c_hammers[1], 0.0, 0.0)\n",
    "#\n",
    "# set_seed(seed)\n",
    "#\n",
    "# logger = setup_logger()\n",
    "#\n",
    "# _, _, test, vocabulary = read_data(task, model_type, logger, clip_vocab, block_words)\n",
    "#\n",
    "# model = get_trained_model(model_type, task, best_epochs[tasks.index(task)], seed, loss_config, vocabulary)\n",
    "\n",
    "\n",
    "# accuracy, loss = evaluate(model, test, vocabulary, loss_config, logger=logger, stage='test', attn_stats=True, num_vis=100)\n",
    "\n",
    "# print('Accuracy: ', accuracy)\n",
    "# print('Loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We have 9 classification models (3 datasets and 3 different regularization values) which can be used with LIME\n",
    "models_list = [\n",
    "    'data/models/model=emb-att_task=occupation-classification_epoch=5_seed=1_hammer=0.00_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=occupation-classification_epoch=1_seed=1_hammer=0.10_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=occupation-classification_epoch=1_seed=1_hammer=1.00_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=pronoun_epoch=1_seed=1_hammer=0.00_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=pronoun_epoch=1_seed=1_hammer=0.10_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=pronoun_epoch=1_seed=1_hammer=1.00_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=sst-wiki_epoch=5_seed=1_hammer=0.00_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=sst-wiki_epoch=3_seed=1_hammer=0.10_rand-entropy=0.00.pt',\n",
    "    'data/models/model=emb-att_task=sst-wiki_epoch=12_seed=1_hammer=1.00_rand-entropy=0.00.pt'\n",
    "]\n",
    "\n",
    "# initialize LIME explainer\n",
    "    class_names = ['surgeon', 'non-surgeon']\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "for model_path in models_list:\n",
    "    explanations = run_lime(model_path, logger, explainer, class_names, block_words, num_explanations=5)\n",
    "\n",
    "    # we should have 5 explanations now --> visualize them\n",
    "    for explanation in explanations:\n",
    "        print(explanation.as_list())\n",
    "\n",
    "        fig = explanation.as_pyplot_figure()\n",
    "        explanation.show_in_notebook(text=False)\n",
    "        explanation.show_in_notebook(text=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Lime Explainer on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms. romeo practices medicine in new hyde park, ny and specializes in pediatric gastroenterology. ms. romeo is affiliated with cohen childrens medical center and north shore university hospital. ms. romeo speaks english, chinese and spanish.\n",
      "Original sentence:  ms. romeo practices medicine in new hyde park, ny and specializes in pediatric gastroenterology. ms. romeo is affiliated with cohen childrens medical center and north shore university hospital. ms. romeo speaks english, chinese and spanish.\n",
      "words from lime are equals indices stored in model\n",
      "softmax dim 0  tensor([4.0808e-07, 1.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "Document ID: 83\n",
      "Original sentence:  ms. romeo practices medicine in new hyde park, ny and specializes in pediatric gastroenterology. ms. romeo is affiliated with cohen childrens medical center and north shore university hospital. ms. romeo speaks english, chinese and spanish.\n",
      "words from lime are equals indices stored in model\n",
      "softmax dim 0  tensor([4.0808e-07, 1.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "Probability (Surgeon) = 0.99999964\n",
      "True class: non-surgeon\n"
     ]
    }
   ],
   "source": [
    "# class_names = ['surgeon', 'non-surgeon']\n",
    "# # class_names = [0, 1]\n",
    "#\n",
    "# explainer = LimeTextExplainer(class_names=class_names)\n",
    "#\n",
    "# idx = 83\n",
    "# test_instance = test[idx]\n",
    "# target = test_instance[4]\n",
    "#\n",
    "# # prediction = model.predict_probabilities(test_instance)\n",
    "# # print('prediction: ', prediction)\n",
    "# # print('target: ', target)\n",
    "#\n",
    "# word_indices = test_instance[1]\n",
    "# words = [vocabulary.i2w[idx] for idx in word_indices]\n",
    "# sentence = ' '.join(words)\n",
    "# print(sentence)\n",
    "#\n",
    "# model.data_instance_for_prediction(test_instance)\n",
    "#\n",
    "# exp = explainer.explain_instance(sentence, model.predict_probabilities, num_features=6)\n",
    "# print('Document ID: %d' % idx)\n",
    "#\n",
    "# prediction = model.predict_probabilities([sentence])[0]\n",
    "# print(f'Probability ({class_names[1]}) =', prediction[1])\n",
    "# print(f'Probability ({class_names[0]}) =', prediction[0])\n",
    "#\n",
    "# print('True class: %s' % class_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.as_list()\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "PyCharm (FACT)",
   "language": "python",
   "name": "pycharm-f84e84a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}