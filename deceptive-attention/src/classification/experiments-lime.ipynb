{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments: Fooling Lime\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data and Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_type = \"emb-att\"\n",
    "nwords\n",
    "\n",
    "current_model = get_model(model_type, nwords, EMB_SIZE, HID_SIZE, ntags)\n",
    "model.load_state_dict(torch.load(DATA_MODELS_PATH + 'model_' + task + suffix + '_seed=' + str(seed) + '_coeff='\n",
    "                                     + str(coeff) + '_num-train=' + str(num_train) + '.pt'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training (with Attention)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# seeds = [1, 13, 42]\n",
    "# original seeds taken from their sh file\n",
    "seeds = [1, 5]\n",
    "\n",
    "coefficients = [0.0, 1.0, 0.1]\n",
    "\n",
    "# tasks = ['copy', 'reverse-copy', 'binary-flip', 'en-hi', 'en-de']\n",
    "# original tasks taken from their sh file\n",
    "\n",
    "tasks = ['copy', 'reverse-copy', 'binary-flip', 'en-de']\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "for seed in seeds:\n",
    "    for coeff in coefficients:\n",
    "        for task in tasks:\n",
    "            train(task, epochs, coeff, seed, batch_size, attentions[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Baselines (without Attention)\n",
    "The authors ran experiments with uniform and no attention (ablation studies) and no penalty on impermissible words (loss coefficient 0.0)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# original seeds taken from their sh file\n",
    "seeds = [6, 10]\n",
    "\n",
    "for seed in seeds:\n",
    "    for task in tasks:\n",
    "        train(task, epochs, 0.0, seed, batch_size, attentions[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results (with Attention)\n",
    "\n",
    "- load pretrained models which we have saved and included in github repo / code\n",
    "- visualize some results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results Baselines (without Attention)\n",
    "- load pretrained models which we have saved and included in github repo / code\n",
    "- visualize some results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## English-German Translation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}