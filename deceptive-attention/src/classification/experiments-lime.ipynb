{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments: Fooling Lime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from data_utils import read_data\n",
    "from train_utils import *\n",
    "from log_utils import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_type = \"emb-att\"\n",
    "# emb_size = 123\n",
    "# hid_size = 123\n",
    "# task_name = 'occupation-classification'\n",
    "# best_epoch = 1\n",
    "# seed = 1\n",
    "# # c_hammer = 0.0\n",
    "# c_entropy = 0.0\n",
    "# clip_vocab = True\n",
    "# block_words = ['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n",
    "#\n",
    "# train, dev, test, n_words, i2w, i2t, n_tags = read_data(task_name,model_type,clip_vocab, block_words)\n",
    "#\n",
    "# model = get_trained_model(model_type, task_name, best_epoch, seed, c_hammer, c_entropy, n_words, emb_size, hid_size, n_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test\n",
    "For three different manipulations: 0.0 (no manipulation), 0.1, 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using block words\n",
      "Using block words\n",
      "Using block words\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/models/model+emb-att_task=occupation-classification_epoch=4_seed=1_hammer=0.10_rand-entropy=0.00.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-7a7979a3f56f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi2w\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi2t\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_tags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclip_vocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock_words\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_trained_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_epochs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_hammer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_entropy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi2w\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi2t\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mattn_stats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_vis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/uva_artificial_intelligence/p3/fact_ai/project/FACT/deceptive-attention/src/classification/train_utils.py\u001B[0m in \u001B[0;36mget_trained_model\u001B[0;34m(model_type, task_name, epoch, seed, c_hammer, c_entropy, n_words, n_tags, emb_size, hid_size)\u001B[0m\n\u001B[1;32m     30\u001B[0m                       hid_size=64):\n\u001B[1;32m     31\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0memb_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhid_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_tags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_model_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc_entropy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_hammer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/attention/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    582\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 584\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    585\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    586\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0m_open_zipfile_reader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/attention/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 234\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    235\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/attention/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 215\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/models/model+emb-att_task=occupation-classification_epoch=4_seed=1_hammer=0.10_rand-entropy=0.00.pt'"
     ]
    }
   ],
   "source": [
    "model_type = \"emb-att\"\n",
    "c_entropy = 0.0\n",
    "clip_vocab = True\n",
    "block_words = ['he', 'she', 'her', 'his', 'him', 'himself', 'herself', 'hers', 'mr', 'mrs', 'ms', 'mr.', 'mrs.', 'ms.']\n",
    "seed = 1\n",
    "\n",
    "c_hammers = [0.0, 0.1, 1.0]\n",
    "tasks = ['sst-wiki', 'pronoun', 'occupation-classification']\n",
    "best_epochs = [1, 2, 4]\n",
    "\n",
    "# for task in tasks:\n",
    "# for now only for single task\n",
    "task = tasks[2]\n",
    "\n",
    "# for c_hammer in c_hammers:\n",
    "# for now only for single hammer\n",
    "c_hammer = c_hammers[1]\n",
    "\n",
    "logger = setup_logger(\".\", f\"task={task}__model={model_type}_hammer={c_hammer}_seed={seed}\")\n",
    "\n",
    "_, _, test, n_words, i2w, i2t, n_tags = read_data(task, model_type, logger, clip_vocab, block_words)\n",
    "\n",
    "model = get_trained_model(model_type, task, best_epochs[tasks.index(task)], seed, c_hammer, c_entropy, n_words, n_tags)\n",
    "accuracy, loss = evaluate(model, test, i2w, i2t, stage='test',attn_stats=True, num_vis=100)\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Lime Explainer on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = ['surgeon', 'non-surgeon']\n",
    "# class_names = [0, 1]\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "idx = 83\n",
    "test_document = test.data[idx]\n",
    "target = test.target[idx]\n",
    "\n",
    "model.predict_probabilities(test_document)[0,1]\n",
    "\n",
    "#\n",
    "# exp = explainer.explain_instance(test_document, model.predict_probabilities, num_features=6)\n",
    "# print('Document ID: %d' % idx)\n",
    "# print('Probability (Surgeon) =', model.predict_probabilities(test_document)[0,1])\n",
    "# print('True class: %s' % class_names[target])"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}