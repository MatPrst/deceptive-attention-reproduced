{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments: Sequence to Sequence\n",
    "\n",
    "This notebook reproduces our reproducibility project during the Fairness, Accountability,\n",
    "Confidentiality and Transparency (FACT) course at University of Amsterdam. Specifically, we reproduce the results from\n",
    "\"Learning to Deceive with Attention-Based Explanations\".\n",
    "\n",
    "While our main code is contained in the folders `classification` and `sequence-to-sequence`, we enable training and\n",
    "visualization via this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !conda init bash\n",
    "# !conda activate attention\n",
    "\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from train import train\n",
    "import numpy as np\n",
    "\n",
    "# from seq2seq.train import evaluate_test\n",
    "\n",
    "# try:\n",
    "#     import pytorch_lightning as pl\n",
    "# except ModuleNotFoundError: # In case PyTorch Lightning is not installed by default.\n",
    "#     !pip install pytorch-lightning==1.0.3\n",
    "#     import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attentions = ['dot-product', 'uniform', 'no-attention']\n",
    "\n",
    "# original seeds for which the authors trained their seq2seq models\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "coefficients = [0.0, 1.0, 0.1]\n",
    "tasks = ['copy', 'reverse-copy', 'binary-flip', 'en-de']\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training: Attention Manipulation\n",
    "\n",
    "For this part of the experiments' attention is computed as dot-product and impermissible words, as defined in our reproducibility report, are penalized.\n",
    "The lambda coefficient (0.0, 0.1 or 1.0) defines respectively if placing attention on these impermissible words is penalized and if so how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training..........\n",
      "Configuration:\n",
      " epochs: 1\n",
      " coeff: 0.0\n",
      " seed: 1\n",
      " batch_size: 128\n",
      " attention: dot-product\n",
      " debug: False\n",
      " num_train: 1000000\n",
      " device: cpu\n",
      " task: copy\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-6c1a00a51940>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mseed\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mseeds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m             \u001B[0mtest_accuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_attention_mass\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_bleu_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcoeff\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattentions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m             \u001B[0maccuracies\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_accuracy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/uva_artificial_intelligence/p3/fact_ai/project/FACT/deceptive-attention/src/seq2seq/train.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(task, coeff, seed, attention, epochs, batch_size, decode_no_att_inference, tensorboard_log, debug, num_train, encoder_emb_dim, decoder_emb_dim, encoder_hid_dim, decoder_hid_dim)\u001B[0m\n\u001B[1;32m    372\u001B[0m     \u001B[0msentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minitialize_sentences\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdebug\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSPLITS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 374\u001B[0;31m     \u001B[0mtrain_batches\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdev_batches\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_batches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_batches_from_sentences\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSRC_LANG\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTRG_LANG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    376\u001B[0m     \u001B[0;31m# setup the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/uva_artificial_intelligence/p3/fact_ai/project/FACT/deceptive-attention/src/seq2seq/batch_utils.py\u001B[0m in \u001B[0;36mget_batches_from_sentences\u001B[0;34m(sentences, batch_size, source_lang, target_lang)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mtest_sentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msentences\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m     \u001B[0mtrain_batches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_batches\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_sentences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msource_lang\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_lang\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[0;31m# don't accept new words from validation and test set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/uva_artificial_intelligence/p3/fact_ai/project/FACT/deceptive-attention/src/seq2seq/batch_utils.py\u001B[0m in \u001B[0;36mget_batches\u001B[0;34m(sentences, batch_size, source_lang, target_lang)\u001B[0m\n\u001B[1;32m    109\u001B[0m                 \u001B[0msrc_i\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_i\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_src_len\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m                 \u001B[0mtrg_j\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrg_j\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_trg_len\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m                 \u001B[0mcurrent_alignment\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrg_j\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msrc_i\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0maligned_outputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_alignment\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "acc_means, att_m_means, bleu_score_means = [], [], []\n",
    "acc_std, att_m_std, bleu_score_std = [], [], []\n",
    "\n",
    "for coeff in coefficients[0:1]:\n",
    "    for task in tasks[0:1]:\n",
    "        accuracies, attention_masses, bleu_scores = [], [], []\n",
    "\n",
    "        for seed in seeds[0:1]:\n",
    "            test_accuracy, test_attention_mass, test_bleu_score = train(task, coeff, seed, attentions[0], epochs)\n",
    "\n",
    "            accuracies.append(test_accuracy)\n",
    "            attention_masses.append(test_attention_mass)\n",
    "            bleu_scores.append(test_bleu_score)\n",
    "\n",
    "        # compute mean and standard deviation\n",
    "        accuracy_std = np.std(np.array(accuracies))\n",
    "        acc_std.append(accuracy_std)\n",
    "\n",
    "        accuracy_mean = np.mean(np.array(accuracies))\n",
    "        acc_means.append(accuracy_mean)\n",
    "\n",
    "print(acc_std)\n",
    "print(acc_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization: Attention Manipulation\n",
    "\n",
    "Compute the means and standard deviations and display"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Baselines (without Attention)\n",
    "The authors ran experiments with uniform and no attention (ablation studies) and no penalty on impermissible words (loss coefficient 0.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# accuracies, attention_masses, bleu_scores = [], [], []\n",
    "#\n",
    "# for seed in seeds[0:1]:\n",
    "#     for task in tasks[0:1]:\n",
    "#         for attention in attentions[1:]:\n",
    "#             test_accuracy, test_attention_mass, test_bleu_score = train(task, 0.0, seed, attention, epochs)\n",
    "#\n",
    "#             accuracies.append(test_accuracy)\n",
    "#             attention_masses.append(test_attention_mass)\n",
    "#             bleu_scores.append(test_bleu_score)\n",
    "#\n",
    "#             # compute mean and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Attention Manipulation\n",
    "\n",
    "- load pretrained models which we have saved and included in github repo / code\n",
    "- visualize some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate_model = ['best', 'latest']\n",
    "#\n",
    "# for seed in seeds:\n",
    "#     for coeff in coefficients:\n",
    "#         for task in tasks:\n",
    "#             loss, acc, attn_mass = evaluate_test(task, coeff, seed, model=evaluate_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = [['Dot-Product',2,3],['Uniform',5,6],['None',8,9], ['Manipulated',8,9], ['Manipulated',8,9]]\n",
    "data_frame = pd.DataFrame(data, columns=['Attention', 'Bigram Flip: Acc.', 'Bigram Flip: A.M.'])\n",
    "\n",
    "def generate_ascii_table(df):\n",
    "    x = PrettyTable()\n",
    "    x.field_names = df.columns.tolist()\n",
    "    for row in df.values:\n",
    "        x.add_row(row)\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "generate_ascii_table(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Baselines (without Attention)\n",
    "- load pretrained models which we have saved and included in github repo / code\n",
    "- visualize some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## English-German Translation"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "PyCharm (FACT)",
   "language": "python",
   "name": "pycharm-f84e84a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}